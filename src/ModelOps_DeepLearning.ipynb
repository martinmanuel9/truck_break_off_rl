{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelOps and Deep Learning Algo\n",
    "The following steps incorporates saving the model within the S3 Bucket to have a model registry as an option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting truck_breakoff_rl_markov.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile truck_breakoff_rl_markov.py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import pathlib\n",
    "from io import StringIO\n",
    "import argparse\n",
    "import joblib\n",
    "\n",
    "# Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "class TruckBreakOffModel:\n",
    "    # saves model within s3 bucket\n",
    "    def model_fn(self, model_dir):\n",
    "        clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "        return clf\n",
    "\n",
    "\n",
    "    def reinforcement_model(self, args):\n",
    "        # Define markov chain\n",
    "        transition_matrix = np.array([[0.9, 0.1],\n",
    "                                      [0.3, 0.7]])\n",
    "\n",
    "        # Define the reward matrix\n",
    "        reward_matrix = np.array([[10, -1],\n",
    "                                  [-1, 10]])\n",
    "\n",
    "        # Define hyperparameters\n",
    "        num_episodes = args.num_episodes\n",
    "        learning_rate = args.learning_rate\n",
    "        discount_factor = args.discount_factor\n",
    "        epsilon = args.epsilon\n",
    "\n",
    "        # Define the Q-network\n",
    "        num_states = transition_matrix.shape[0]\n",
    "        num_actions = transition_matrix.shape[1]\n",
    "        W = tf.Variable(tf.random.uniform([num_states, num_actions], 0, 0.01))\n",
    "        W = tf.transpose(W)\n",
    "\n",
    "        # Define placeholders for state, action, and target Q-value\n",
    "        state_ph = tf.compat.v1.placeholder(tf.int32, shape=[])\n",
    "        action_ph = tf.compat.v1.placeholder(tf.int32, shape=[])\n",
    "        target_q_value_ph = tf.compat.v1.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        # Compute Q-value of current state\n",
    "        one_hot_state = tf.one_hot(state_ph, num_states)\n",
    "        one_hot_state = tf.reshape(one_hot_state, [1, -1])  # Reshape to match the shape of W\n",
    "        Q_values = tf.matmul(one_hot_state, tf.transpose(W))\n",
    "\n",
    "        # Define loss\n",
    "        updated_Q_values = tf.tensor_scatter_nd_update(Q_values, [[0, action_ph]], [target_q_value_ph])\n",
    "        loss = tf.reduce_sum(tf.square(updated_Q_values - Q_values))\n",
    "\n",
    "        # Define optimizer\n",
    "        optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "        # Define training operation\n",
    "        train_op = optimizer.minimize(loss)\n",
    "\n",
    "        # Start TensorFlow session\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            # Initialize variables\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            # Training loop\n",
    "            for episode in range(num_episodes):\n",
    "                state = np.random.randint(0, num_states)  # Start at a random state\n",
    "                while True:\n",
    "                    # Choose action (epsilon-greedy)\n",
    "                    if np.random.rand() < epsilon:\n",
    "                        action = np.random.randint(0, num_actions)\n",
    "                    else:\n",
    "                        action = sess.run(tf.argmax(Q_values, 1), feed_dict={state_ph: state})\n",
    "\n",
    "                    # Perform action and observe next state\n",
    "                    next_state = np.random.choice(range(num_states), p=transition_matrix[state])\n",
    "\n",
    "                    # Compute reward\n",
    "                    reward = reward_matrix[state, action]\n",
    "\n",
    "                    # Compute target Q-value\n",
    "                    max_Q_next = np.max(sess.run(Q_values, feed_dict={state_ph: next_state}))\n",
    "                    target_Q_value = reward + discount_factor * max_Q_next\n",
    "\n",
    "                    # Update Q-value\n",
    "                    _ = sess.run(train_op, feed_dict={state_ph: state, action_ph: action, target_q_value_ph: target_Q_value})\n",
    "\n",
    "                    state = next_state\n",
    "                    if state == 0:  # Reached terminal state\n",
    "                        break\n",
    "\n",
    "            # Get learned Q-values\n",
    "            learned_Q_values = sess.run(Q_values)\n",
    "       \n",
    "\n",
    "        # Print the learned Q-values\n",
    "        print(\"Learned Q-values:\")\n",
    "        print(learned_Q_values)\n",
    "        # After training is complete, assign the learned values to instance attributes\n",
    "        self.learned_Q_values = learned_Q_values\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.reward_matrix = reward_matrix\n",
    "\n",
    "        return learned_Q_values, transition_matrix, reward_matrix\n",
    "\n",
    "    def evaluate_model(self, learned_Q_values, transition_matrix, reward_matrix):\n",
    "        num_states = transition_matrix.shape[0]\n",
    "        num_actions = transition_matrix.shape[1]\n",
    "        \n",
    "        # Initialize the cumulative return\n",
    "        total_return = 0\n",
    "\n",
    "        # Run episodes to compute the return\n",
    "        num_episodes = 1000  # You can adjust this number\n",
    "        for _ in range(num_episodes):\n",
    "            state = np.random.randint(0, num_states)\n",
    "            episode_return = 0\n",
    "            while True:\n",
    "                action = np.argmax(learned_Q_values[state])\n",
    "                next_state = np.random.choice(range(num_states), p=transition_matrix[state])\n",
    "                reward = reward_matrix[state, action]\n",
    "                episode_return += reward\n",
    "                state = next_state\n",
    "                if state == 0:  # Reached terminal state\n",
    "                    break\n",
    "            total_return += episode_return\n",
    "\n",
    "        average_return = total_return / num_episodes\n",
    "        return average_return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[INFO] Extracting arguments...\")\n",
    "    print()\n",
    "    truck_break_off_mdl = TruckBreakOffModel()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "    # Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--num_episodes\", type=int, default=1000)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--discount_factor\", type=float, default=0.95)\n",
    "    parser.add_argument(\"--epsilon\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--num_states\", type=int, default=2)\n",
    "    parser.add_argument(\"--num_actions\", type=int, default=2)\n",
    "    parser.add_argument(\"--num_features\", type=int, default=7)\n",
    " \n",
    "    # Data, model, and output directories\n",
    "    # sets the SageMaker environment within SageMaker\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAINING\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TESTING\"))\n",
    "\n",
    "    # test/train files\n",
    "    parser.add_argument(\"--train_file\", type=str, default=\"train-V1.csv\")\n",
    "    parser.add_argument(\"--test_file\", type=str, default=\"test-V1.csv\")\n",
    "\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"[INFO] Reading data...\")\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"Train Dataset:\\n\", train_df.head())\n",
    "    print()\n",
    "    print(\"Test Dataset:\\n\", test_df.head())\n",
    "    print()\n",
    "\n",
    "\n",
    "    print(\"[INFO] Building Training & Testing Datasets...\")\n",
    "    print()\n",
    "    features = ['ROUTEID', 'LAST_EDITED_DATE','FROMDATE', 'TODATE', 'FROMMEASURE', 'TOMEASURE', 'TRUCK_BREAK_OFF']\n",
    "    label = 'LABEL'\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[label]\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print(\"[INFO] Training Model...\")\n",
    "    print()\n",
    "\n",
    "    # send to S3 bucket. SageMaker will take training data from the S3 bucket\n",
    "    sk_prefix = \"sagemaker/truck-break-off/datasets\" # sagemaker environment\n",
    "    model_dir = args.model_dir\n",
    "\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(truck_break_off_mdl.reinforcement_model, model_path)\n",
    "    print(\"Model saved at: {}\".format(model_path))\n",
    "    print()\n",
    "\n",
    "    print(\"[INFO] Model Training Complete...\")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Training of Model\n",
    "Must get sagemaker role from IAM. In this particular instance we took an existing role for sagemaker (execution role) to enable this functionality. This role is usually provided by AWS or you can create one specific for you. Different roles and images can have CPU and GPU and there is a cost associated to these depending on time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "FRAMEWORK_VERSION = \"2.7.0\"\n",
    "\n",
    "# Specify the image URI for TensorFlow\n",
    "# image_uri = f\"763104351884.dkr.ecr.us-west-1.amazonaws.com/tensorflow-training:{FRAMEWORK_VERSION}-cpu-py37-ubuntu18.04\"\n",
    "image_uri = f\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-ubuntu20.04-sagemaker\"\n",
    "\n",
    "# Create a TensorFlow estimator\n",
    "tensorflow_estimator = TensorFlow(\n",
    "    entry_point=\"truck_breakoff_rl_markov.py\",\n",
    "    # role=\"arn:aws:iam::174023208515:role/service-role/AmazonSageMaker-ExecutionRole-20240321T161040\", # get from aws roles\n",
    "    role= \"arn:aws:iam::174023208515:role/sagemaker-truck-break-off-role\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    image_uri=image_uri,\n",
    "    base_job_name=\"truck-breakoff-rl-markov\",\n",
    "    hyperparameters={\n",
    "        \"num_episodes\": 1000,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"discount_factor\": 0.95,\n",
    "        \"epsilon\": 0.1,\n",
    "        \"num_states\": 2,\n",
    "        \"num_actions\": 2,\n",
    "        \"num_features\": 7,\n",
    "    },\n",
    "    use_spot_instances=True,\n",
    "    max_wait=7200,\n",
    "    max_run=3600,\n",
    "    output_path= \"s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous call to launch training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: truck-breakoff-rl-markov-2024-04-08-19-30-32-177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-08 19:30:33 Starting - Starting the training job...\n",
      "2024-04-08 19:30:50 Starting - Preparing the instances for training...\n",
      "2024-04-08 19:31:29 Downloading - Downloading input data...\n",
      "2024-04-08 19:31:49 Downloading - Downloading the training image...\n",
      "2024-04-08 19:32:35 Training - Training image download completed. Training in progress..2024-04-08 19:32:43.919230: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 19:32:46,099 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2024-04-08 19:32:46,100 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-04-08 19:32:46,100 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-08 19:32:46,446 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-04-08 19:32:46,447 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-08 19:32:46,458 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-04-08 19:32:46,458 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-08 19:32:46,470 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-04-08 19:32:46,470 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-08 19:32:46,481 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"discount_factor\": 0.95,\n",
      "        \"epsilon\": 0.1,\n",
      "        \"learning_rate\": 0.1,\n",
      "        \"model_dir\": \"s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/model\",\n",
      "        \"num_actions\": 2,\n",
      "        \"num_episodes\": 1000,\n",
      "        \"num_features\": 7,\n",
      "        \"num_states\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"truck-breakoff-rl-markov-2024-04-08-19-30-32-177\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://martymdlregistry/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"truck_breakoff_rl_markov\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"truck_breakoff_rl_markov.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"discount_factor\":0.95,\"epsilon\":0.1,\"learning_rate\":0.1,\"model_dir\":\"s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/model\",\"num_actions\":2,\"num_episodes\":1000,\"num_features\":7,\"num_states\":2}\n",
      "SM_USER_ENTRY_POINT=truck_breakoff_rl_markov.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"testing\",\"training\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=truck_breakoff_rl_markov\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=0\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://martymdlregistry/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"discount_factor\":0.95,\"epsilon\":0.1,\"learning_rate\":0.1,\"model_dir\":\"s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/model\",\"num_actions\":2,\"num_episodes\":1000,\"num_features\":7,\"num_states\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"truck-breakoff-rl-markov-2024-04-08-19-30-32-177\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://martymdlregistry/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/source/sourcedir.tar.gz\",\"module_name\":\"truck_breakoff_rl_markov\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"truck_breakoff_rl_markov.py\"}\n",
      "SM_USER_ARGS=[\"--discount_factor\",\"0.95\",\"--epsilon\",\"0.1\",\"--learning_rate\",\"0.1\",\"--model_dir\",\"s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/model\",\"--num_actions\",\"2\",\"--num_episodes\",\"1000\",\"--num_features\",\"7\",\"--num_states\",\"2\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TESTING=/opt/ml/input/data/testing\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_HP_DISCOUNT_FACTOR=0.95\n",
      "SM_HP_EPSILON=0.1\n",
      "SM_HP_LEARNING_RATE=0.1\n",
      "SM_HP_MODEL_DIR=s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/model\n",
      "SM_HP_NUM_ACTIONS=2\n",
      "SM_HP_NUM_EPISODES=1000\n",
      "SM_HP_NUM_FEATURES=7\n",
      "SM_HP_NUM_STATES=2\n",
      "PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python310.zip:/usr/local/lib/python3.10:/usr/local/lib/python3.10/lib-dynload:/usr/local/lib/python3.10/site-packages:/usr/local/lib/python3.10/site-packages/smdebug-1.0.33-py3.10.egg:/usr/local/lib/python3.10/site-packages/pyinstrument-3.4.2-py3.10.egg:/usr/local/lib/python3.10/site-packages/pyinstrument_cext-0.2.4-py3.10-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/usr/local/bin/python3.10 truck_breakoff_rl_markov.py --discount_factor 0.95 --epsilon 0.1 --learning_rate 0.1 --model_dir s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/model --num_actions 2 --num_episodes 1000 --num_features 7 --num_states 2\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.10/site-packages/horovod/torch/mpi_lib_v2.cpython-310-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still available.\n",
      "[INFO] Extracting arguments...\n",
      "[INFO] Reading data...\n",
      "Train Dataset:\n",
      "NAME   ROUTEID  FROMMEASURE  ...  SHAPELEN  TRUCK_BREAK_OFF  LABEL\n",
      "0  Primary Route  0.253247     0.020921  ...         0              0.0      0\n",
      "1  Primary Route  0.032468     0.270799  ...         0              1.0      0\n",
      "2  Primary Route  0.915584     0.000000  ...         0              1.0      1\n",
      "3  Primary Route  0.350649     0.001946  ...         0              0.0      0\n",
      "4  Primary Route  0.168831     0.170770  ...         0              1.0      1\n",
      "[5 rows x 18 columns]\n",
      "Test Dataset:\n",
      "NAME   ROUTEID  FROMMEASURE  ...  SHAPELEN  TRUCK_BREAK_OFF  LABEL\n",
      "0  Primary Route  0.493506     0.015082  ...         0              0.0      0\n",
      "1  Primary Route  0.422078     0.197626  ...         0              1.0      1\n",
      "2  Primary Route  0.487013     0.040965  ...         0              1.0      0\n",
      "3  Primary Route  0.097403     0.302131  ...         0              1.0      0\n",
      "4  Primary Route  0.129870     0.557750  ...         0              1.0      1\n",
      "[5 rows x 18 columns]\n",
      "[INFO] Building Training & Testing Datasets...\n",
      "[INFO] Training Model...\n",
      "Model saved at: /opt/ml/model/model.joblib\n",
      "[INFO] Model Training Complete...\n",
      "2024-04-08 19:32:50,074 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-04-08 19:32:50,074 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-04-08 19:32:50,074 sagemaker_tensorflow_container.training WARNING  Your model will NOT be servable with SageMaker TensorFlow Serving container. The model artifact was not saved in the TensorFlow SavedModel directory structure:\n",
      "https://www.tensorflow.org/guide/saved_model#structure_of_a_savedmodel_directory\n",
      "2024-04-08 19:32:50,074 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-04-08 19:33:06 Uploading - Uploading generated training model\n",
      "2024-04-08 19:33:06 Completed - Training job completed\n",
      "Training seconds: 97\n",
      "Billable seconds: 47\n",
      "Managed Spot Training savings: 51.5%\n"
     ]
    }
   ],
   "source": [
    "# Launch training job with an async call\n",
    "train_path = \"s3://martymdlregistry/sagemaker/truck-break-off/datasets/train-V1.csv\"\n",
    "test_path = \"s3://martymdlregistry/sagemaker/truck-break-off/datasets/test-V1.csv\"\n",
    "\n",
    "tensorflow_estimator.fit({\"training\": train_path, \"testing\": test_path})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show where the model is stored in the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket martymdlregistry\n",
      "\n",
      "2024-04-08 19:33:06 Starting - Preparing the instances for training\n",
      "2024-04-08 19:33:06 Downloading - Downloading the training image\n",
      "2024-04-08 19:33:06 Training - Training image download completed. Training in progress.\n",
      "2024-04-08 19:33:06 Uploading - Uploading generated training model\n",
      "2024-04-08 19:33:06 Completed - Training job completed\n",
      "Model artifact persisted at s3://martymdlregistry/sagemaker/truck-break-off/models/deep_learning/truck-breakoff-rl-markov-2024-04-08-19-30-32-177/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# creating a client for sagemaker\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "# creating a session for sagemaker\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Need to create an S3 bucket\n",
    "bucket = 'martymdlregistry' # specific s3 bucket\n",
    "print('Using bucket ' + bucket)\n",
    "\n",
    "tensorflow_estimator.latest_training_job.wait(logs=\"None\")\n",
    "\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=tensorflow_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(\"Model artifact persisted at \" + artifact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Capbility for Deployment\n",
    "\n",
    "We want to keep a copy so that we can deploy a specific model at an endpoint (App)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: tensorflow-training-2024-04-08-19-34-20-942\n",
      "INFO:sagemaker:Creating endpoint-config with name truckBreakOffModelDeepLearningEndpoint-2024-04-08-19-34-18\n",
      "INFO:sagemaker:Creating endpoint with name truckBreakOffModelDeepLearningEndpoint-2024-04-08-19-34-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint truckBreakOffModelDeepLearningEndpoint-2024-04-08-19-34-18: Failed. Reason: CannotStartContainerError. Please ensure the model container for variant AllTraffic starts correctly when invoked with 'docker run <image> serve'. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m tensorflow_model \u001b[38;5;241m=\u001b[39m TensorFlowModel(model_data\u001b[38;5;241m=\u001b[39martifact,\n\u001b[1;32m      8\u001b[0m                                     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marn:aws:iam::174023208515:role/sagemaker-truck-break-off-role\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                     framework_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.7.0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                     image_uri\u001b[38;5;241m=\u001b[39mimage_uri)\n\u001b[1;32m     12\u001b[0m endpoint_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruckBreakOffModelDeepLearningEndpoint-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m strftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, gmtime())\n\u001b[0;32m---> 14\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mtensorflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mml.m4.xlarge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.8/site-packages/sagemaker/tensorflow/model.py:356\u001b[0m, in \u001b[0;36mTensorFlowModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe TensorFlow version \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support EIA.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework_version\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTensorFlowModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_instance_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_recommendation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_recommendation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.8/site-packages/sagemaker/model.py:1662\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1660\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1675\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.8/site-packages/sagemaker/session.py:5635\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\u001b[0m\n\u001b[1;32m   5632\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   5633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 5635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.8/site-packages/sagemaker/session.py:4493\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait, live_logging)\u001b[0m\n\u001b[1;32m   4490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_arn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpointArn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   4492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4493\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.8/site-packages/sagemaker/session.py:5278\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll, live_logging)\u001b[0m\n\u001b[1;32m   5272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   5273\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   5274\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   5275\u001b[0m             allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   5276\u001b[0m             actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   5277\u001b[0m         )\n\u001b[0;32m-> 5278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   5279\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   5280\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   5281\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   5282\u001b[0m     )\n\u001b[1;32m   5283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint truckBreakOffModelDeepLearningEndpoint-2024-04-08-19-34-18: Failed. Reason: CannotStartContainerError. Please ensure the model container for variant AllTraffic starts correctly when invoked with 'docker run <image> serve'. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from time import gmtime, strftime # type: ignore\n",
    "\n",
    "model_name = \"truckBreakOffModelDeepLearning\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "image_uri = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-ubuntu20.04-sagemaker\"\n",
    "\n",
    "tensorflow_model = TensorFlowModel(model_data=artifact,\n",
    "                                    role=\"arn:aws:iam::174023208515:role/sagemaker-truck-break-off-role\",\n",
    "                                    framework_version=\"2.7.0\",\n",
    "                                    image_uri=image_uri)\n",
    "\n",
    "endpoint_name = \"truckBreakOffModelDeepLearningEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "predictor = tensorflow_model.deploy(initial_instance_count=1,\n",
    "                                    instance_type=\"ml.m4.xlarge\",\n",
    "                                    endpoint_name=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.tensorflow.estimator.TensorFlow at 0x30f8406a0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows sagemaker predictor based on the Deep Learning Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truckBreakOffModelDeepLearning-2024-04-08-19-01-23'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Endpoint\n",
    "Having endpoints will incur cost overtime if this is just an experiment. Endpoints will help manage the live applications. You will need to determine what endpoints are in production or in experiment/staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelOps\n",
    "The following steps incorporates saving the model within the S3 Bucket to have a model registry as an option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting truck_breakoff_rl_markov.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile truck_breakoff_rl_markov.py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import pathlib\n",
    "from io import StringIO\n",
    "import argparse\n",
    "import joblib\n",
    "\n",
    "class TruckBreakOffModel:\n",
    "    # saves model within s3 bucket\n",
    "    def model_fn(self, model_dir):\n",
    "        clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "        return clf\n",
    "\n",
    "\n",
    "    def reinforcement_model(self):\n",
    "        # Define markov chain\n",
    "        # Define the transition matrix (Markov chain)\n",
    "        self.transition_matrix = np.array([[0.9, 0.1],\n",
    "                                    [0.3, 0.7]])\n",
    "\n",
    "        # Define the reward matrix\n",
    "        self.reward_matrix = np.array([[10, -1],\n",
    "                                [-1, 10]])\n",
    "\n",
    "        # Define hyperparameters\n",
    "        num_episodes = 1000\n",
    "        learning_rate = 0.1\n",
    "        discount_factor = 0.95\n",
    "        epsilon = 0.1\n",
    "\n",
    "        # Define the Q-network\n",
    "        num_states = self.transition_matrix.shape[0]\n",
    "        num_actions = self.transition_matrix.shape[1]\n",
    "        num_features = 4  # Number of features in your input data\n",
    "        W = tf.Variable(tf.random.uniform([num_states, num_actions], 0, 0.01))\n",
    "        W = tf.transpose(W)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "        # Initialize TensorFlow session\n",
    "        for episode in range(num_episodes):\n",
    "            state = np.random.randint(0, num_states)  # Start at a random state\n",
    "            one_hot_state = 0.0  # Initialize one_hot_state outside the if-else block\n",
    "            while True:\n",
    "                # Choose action (epsilon-greedy)\n",
    "                if np.random.rand() < epsilon:\n",
    "                    action = np.random.randint(0, num_actions)\n",
    "                else:\n",
    "                    one_hot_state = tf.reshape(tf.one_hot(state, num_states), [1, -1])\n",
    "                    # one_hot_state = tf.reshape(tf.one_hot(state, num_states), [1, 1, num_states])\n",
    "\n",
    "                    action = tf.argmax(tf.matmul(one_hot_state, W), 1).numpy()[0]\n",
    "                # Perform action and observe next state and reward\n",
    "                next_state = np.random.choice(range(num_states), p= self.transition_matrix[state])\n",
    "                hot_next_state = tf.reshape(tf.one_hot(next_state, num_states), [1, -1])\n",
    "                reward = self.reward_matrix[state, action]\n",
    "                # Compute Q-value of next state\n",
    "                Q_next = tf.matmul(hot_next_state, W)\n",
    "                # Update Q-value of current state\n",
    "                max_Q_next = tf.reduce_max(Q_next)\n",
    "                target_Q_values = tf.matmul(hot_next_state, W)\n",
    "                \n",
    "                # Update Q-value of current state\n",
    "                target_Q_values_updated = tf.identity(target_Q_values)  # Create a copy\n",
    "                target_Q_values_updated = tf.tensor_scatter_nd_update(target_Q_values_updated, [[0, action]], [reward + discount_factor * max_Q_next])\n",
    "\n",
    "                # Train Q-network\n",
    "                with tf.GradientTape() as tape:\n",
    "                    Q_values = tf.matmul(one_hot_state, W)\n",
    "                    loss = tf.reduce_sum(tf.square(target_Q_values_updated - Q_values))\n",
    "\n",
    "                gradients = tape.gradient(loss, [W])\n",
    "                optimizer.apply_gradients(zip(gradients, [W]))\n",
    "                state = next_state\n",
    "                if state == 0:  # Reached terminal state\n",
    "                    break\n",
    "       \n",
    "        # Print the learned Q-values\n",
    "        print(\"Learned Q-values:\")\n",
    "        print(W.numpy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[INFO] Extracting arguments...\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    truck_break_off_mdl = TruckBreakOffModel()\n",
    "    truck_break_off_mdl.reinforcement_model()\n",
    "    transition_matrix = truck_break_off_mdl.transition_matrix\n",
    "    reward_matrix = truck_break_off_mdl.reward_matrix\n",
    "\n",
    "    # Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--num_episodes\", type=int, default=1000)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--discount_factor\", type=float, default=0.95)\n",
    "    parser.add_argument(\"--epsilon\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--num_states\", type=int, default=transition_matrix.shape[0])\n",
    "    parser.add_argument(\"--num_actions\", type=int, default=transition_matrix.shape[1])\n",
    "    parser.add_argument(\"--num_features\", type=int, default=7)\n",
    "\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    # sets the SageMaker environment within SageMaker\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAINING\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TESTING\"))\n",
    "\n",
    "    # test/train files\n",
    "    # parser.add_argument(\"--train_file\", type=str, default=\"s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/train-V1.csv\")\n",
    "    # parser.add_argument(\"--test_file\", type=str, default=\"s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/test-V1.csv\")\n",
    "\n",
    "    parser.add_argument(\"--train_file\", type=str, default=\"train-V1.csv\")\n",
    "    parser.add_argument(\"--test_file\", type=str, default=\"test-V1.csv\")\n",
    "\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"[INFO] Reading data...\")\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"Train Dataset:\\n\", train_df.head())\n",
    "    print()\n",
    "    print(\"Test Dataset:\\n\", test_df.head())\n",
    "    print()\n",
    "\n",
    "\n",
    "    print(\"[INFO] Building Training & Testing Datasets...\")\n",
    "    print()\n",
    "    features = ['ROUTEID', 'LAST_EDITED_DATE','FROMDATE', 'TODATE', 'FROMMEASURE', 'TOMEASURE', 'TRUCK_BREAK_OFF']\n",
    "    label = 'LABEL'\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[label]\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print(\"[INFO] Training Model...\")\n",
    "    print()\n",
    "\n",
    "    # send to S3 bucket. SageMaker will take training data from the S3 bucket\n",
    "    sk_prefix = \"sagemaker/truck-break-off-rl_markov/datasets\" # sagemaker environment\n",
    "    model_dir = args.model_dir\n",
    "    truck_break_off_mdl.reinforcement_model()\n",
    "    truck_break_off_mdl.model_fn(model_dir)\n",
    "    \n",
    "\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(truck_break_off_mdl.reinforcement_model, model_path)\n",
    "    print(\"Model saved at: {}\".format(model_path))\n",
    "    print()\n",
    "\n",
    "    print(\"[INFO] Model Training Complete...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sagemaker Training of Model\n",
    "Must get sagemaker role from IAM. In this particular instance we took an existing role for sagemaker (execution role) to enable this functionality. This role is usually provided by AWS or you can create one specific for you. Different roles and images can have CPU and GPU and there is a cost associated to these depending on time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "FRAMEWORK_VERSION = \"2.7.0\"\n",
    "\n",
    "# Specify the image URI for TensorFlow\n",
    "# image_uri = f\"763104351884.dkr.ecr.us-west-1.amazonaws.com/tensorflow-training:{FRAMEWORK_VERSION}-cpu-py37-ubuntu18.04\"\n",
    "image_uri = f\"763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-ubuntu20.04-sagemaker\"\n",
    "\n",
    "# Create a TensorFlow estimator\n",
    "tensorflow_estimator = TensorFlow(\n",
    "    entry_point=\"truck_breakoff_rl_markov.py\",\n",
    "    role=\"arn:aws:iam::174023208515:role/service-role/AmazonSageMaker-ExecutionRole-20240321T161040\", # get from aws roles\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    image_uri=image_uri,\n",
    "    base_job_name=\"truck-breakoff-rl-markov\",\n",
    "    hyperparameters={\n",
    "        \"num_episodes\": 1000,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"discount_factor\": 0.95,\n",
    "        \"epsilon\": 0.1,\n",
    "        \"num_states\": 2,\n",
    "        \"num_actions\": 2,\n",
    "        \"num_features\": 7,\n",
    "    },\n",
    "    use_spot_instances=True,\n",
    "    max_wait=7200,\n",
    "    max_run=3600,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous call to launch training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataNotFoundError",
     "evalue": "Unable to load data for: endpoints",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/train-V1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/test-V1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m truck_breakoff_mdl \u001b[38;5;241m=\u001b[39m \u001b[43mtensorflow_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtesting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/estimator.py:1335\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;129m@runnable_by_pipeline\u001b[39m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     experiment_config: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1278\u001b[0m ):\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model using the input training dataset.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[1;32m   1281\u001b[0m \u001b[38;5;124;03m    The API calls the Amazon SageMaker CreateTrainingJob API to start\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;124;03m        :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1337\u001b[0m     experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m _TrainingJob\u001b[38;5;241m.\u001b[39mstart_new(\u001b[38;5;28mself\u001b[39m, inputs, experiment_config)\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/estimator.py:3515\u001b[0m, in \u001b[0;36mFramework._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   3507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set hyperparameters needed for training. This method will also validate ``source_dir``.\u001b[39;00m\n\u001b[1;32m   3509\u001b[0m \n\u001b[1;32m   3510\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;124;03m            constructor if applicable.\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3515\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFramework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_set_debugger_configs()\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/estimator.py:890\u001b[0m, in \u001b[0;36mEstimatorBase._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39ms3_path_join(\n\u001b[1;32m    889\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 890\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    891\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mdefault_bucket_prefix,\n\u001b[1;32m    892\u001b[0m             with_end_slash\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    893\u001b[0m         )\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_output_path_set_from_default_bucket_and_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_config:\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/session.py:586\u001b[0m, in \u001b[0;36mSession.default_bucket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m default_bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_bucket_name_override\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m default_bucket:\n\u001b[0;32m--> 586\u001b[0m     default_bucket \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_default_sagemaker_bucket_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_bucket_set_by_sdk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_s3_bucket_if_it_does_not_exist(\n\u001b[1;32m    590\u001b[0m     bucket_name\u001b[38;5;241m=\u001b[39mdefault_bucket,\n\u001b[1;32m    591\u001b[0m     region\u001b[38;5;241m=\u001b[39mregion,\n\u001b[1;32m    592\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/session.py:7340\u001b[0m, in \u001b[0;36mgenerate_default_sagemaker_bucket_name\u001b[0;34m(boto_session)\u001b[0m\n\u001b[1;32m   7333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates a name for the default sagemaker S3 bucket.\u001b[39;00m\n\u001b[1;32m   7334\u001b[0m \n\u001b[1;32m   7335\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   7336\u001b[0m \u001b[38;5;124;03m    boto_session (boto3.session.Session): The underlying Boto3 session which AWS service\u001b[39;00m\n\u001b[1;32m   7337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7338\u001b[0m region \u001b[38;5;241m=\u001b[39m boto_session\u001b[38;5;241m.\u001b[39mregion_name\n\u001b[1;32m   7339\u001b[0m account \u001b[38;5;241m=\u001b[39m boto_session\u001b[38;5;241m.\u001b[39mclient(\n\u001b[0;32m-> 7340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msts\u001b[39m\u001b[38;5;124m\"\u001b[39m, region_name\u001b[38;5;241m=\u001b[39mregion, endpoint_url\u001b[38;5;241m=\u001b[39m\u001b[43msts_regional_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7341\u001b[0m )\u001b[38;5;241m.\u001b[39mget_caller_identity()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   7342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msagemaker-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(region, account)\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/utils.py:681\u001b[0m, in \u001b[0;36msts_regional_endpoint\u001b[0;34m(region)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/sagemaker/utils.py:755\u001b[0m, in \u001b[0;36m_botocore_resolver\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/botocore/loaders.py:471\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(self, name)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/botocore/loaders.py:142\u001b[0m, in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/truck_break_off_rl/myenv/lib/python3.11/site-packages/botocore/loaders.py:453\u001b[0m, in \u001b[0;36mload_data_with_path\u001b[0;34m(self, name)\u001b[0m\n",
      "\u001b[0;31mDataNotFoundError\u001b[0m: Unable to load data for: endpoints"
     ]
    }
   ],
   "source": [
    "# Launch training job with an async call\n",
    "train_path = \"s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/train-V1.csv\"\n",
    "test_path = \"s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/test-V1.csv\"\n",
    "\n",
    "truck_breakoff_mdl = tensorflow_estimator.fit({\"training\": train_path, \"testing\": test_path})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

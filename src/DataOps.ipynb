{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataOps onto S3 Bucket in AWS\n",
    "The intent of this notebook is to develop a test/train datasets for Sagemaker Studio. This notebook goes step-by-step on ingesting data onto an S3 bucket so that we can connect to Sagemaker. This component addresses data engineer, feature selection, and feature extraction and provides a Data Scientist the test/train datasets to begin experimentation, model training, and begin the data science work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket martymdlregistry\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# creating a client for sagemaker\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "# creating a session for sagemaker\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Need to create an S3 bucket\n",
    "bucket = 'martymdlregistry' # specific s3 bucket\n",
    "print('Using bucket ' + bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Information\n",
    "We have downloaded the Metro DC Truck routes from the following source: https://opendata.dc.gov/datasets/DCGIS::truck-and-bus-through-route/about \n",
    "\n",
    "We now initialize the dataset and conduct featur development and develop synthetic data. The synthetic data we include is the labels as well as the truck_break_off flag. This should emulate when a truck successfully broke off from the route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/martinlopez/Documents/GitHub/truck_break_off_rl/dataset\n",
      "Dataset:\n",
      "             NAME   ROUTEID  FROMMEASURE  TOMEASURE  FROMDATE  TODATE  \\\n",
      "0  Primary Route  0.032468     0.963219   0.970934  0.517427     0.0   \n",
      "1  Primary Route  0.032468     0.756349   0.757947  0.517427     0.0   \n",
      "2  Primary Route  0.032468     0.107424   0.115388  0.517427     0.0   \n",
      "3  Primary Route  0.032468     1.000000   1.000000  0.517427     0.0   \n",
      "4  Primary Route  0.032468     0.775713   0.783222  0.517427     0.0   \n",
      "\n",
      "                                  EVENTID  LOCERROR CREATED_USER CREATED_DATE  \\\n",
      "0  {95A11B7D-E871-4A60-841D-4EE8B490B7D1}  NO ERROR          NaN          NaN   \n",
      "1  {7108E69C-3464-4FF5-8A2E-38EF961B2E23}  NO ERROR          NaN          NaN   \n",
      "2  {9AE842B8-98E4-4D5B-9EE8-73AE4CE25B25}  NO ERROR          NaN          NaN   \n",
      "3  {0555805C-A411-4FD0-BD99-6E3D5AE1446C}  NO ERROR          NaN          NaN   \n",
      "4  {279C06E7-BC10-4BF6-A49D-A185FC44132D}  NO ERROR          NaN          NaN   \n",
      "\n",
      "  LAST_EDITED_USER  LAST_EDITED_DATE  SE_ANNO_CAD_DATA  OBJECTID  SHAPE  \\\n",
      "0               RH      4.173894e-08               NaN    151682    NaN   \n",
      "1               RH      4.173894e-08               NaN    151683    NaN   \n",
      "2               RH      4.173894e-08               NaN    151684    NaN   \n",
      "3               RH      4.173894e-08               NaN    151685    NaN   \n",
      "4               RH      4.173894e-08               NaN    151686    NaN   \n",
      "\n",
      "   SHAPELEN  TRUCK_BREAK_OFF  LABEL  \n",
      "0         0              1.0      0  \n",
      "1         0              0.0      1  \n",
      "2         0              1.0      1  \n",
      "3         0              1.0      1  \n",
      "4         0              1.0      0  \n",
      "\n",
      "Train set:\n",
      " (1636, 18)\n",
      "Test set:\n",
      " (410, 18)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(os.getcwd())\n",
    "# Change the directory to 'dataset'\n",
    "os.chdir('../dataset')\n",
    "# Path to the CSV file\n",
    "csv_file = 'Truck_and_Bus_Through_Route.csv'\n",
    "\n",
    "# Read the CSV file into a dataframe\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# define feature TRUCK_BREAK_OFF\n",
    "df['TRUCK_BREAK_OFF'] = 0\n",
    "# capture labels\n",
    "df['LABEL'] = 0\n",
    "df['LABEL'] = [random.randint(0, 1) for _ in range(len(df))]\n",
    "\n",
    "# Randomize 0s and 1s for the column TRUCK_BREAK_OFF\n",
    "df['TRUCK_BREAK_OFF'] = [random.randint(0, 1) for _ in range(len(df))]\n",
    "\n",
    " # Data preprocessing\n",
    "df['LAST_EDITED_DATE'] = pd.to_datetime(df['LAST_EDITED_DATE'])\n",
    "df['FROMDATE'] = pd.to_datetime(df['FROMDATE'])\n",
    "df['TODATE'] = pd.to_datetime(df['TODATE'])\n",
    "# Convert datetime to Unix timestamp\n",
    "df['LAST_EDITED_DATE'] = df['LAST_EDITED_DATE'].astype(int)\n",
    "df['FROMDATE'] = df['FROMDATE'].astype(int)\n",
    "df['TODATE'] = df['TODATE'].astype(int)\n",
    "df['FROMMEASURE'] = df['FROMMEASURE'].astype(int)\n",
    "df['TOMEASURE'] = df['TOMEASURE'].astype(int)\n",
    "df['ROUTEID'] = df['ROUTEID'].astype('category').cat.codes\n",
    "\n",
    "## normalization\n",
    "scaler = MinMaxScaler()\n",
    "df[['ROUTEID', 'LAST_EDITED_DATE', 'TRUCK_BREAK_OFF', 'FROMDATE', 'TODATE', 'FROMMEASURE', 'TOMEASURE']] = scaler.fit_transform(\n",
    "df[['ROUTEID', 'LAST_EDITED_DATE', 'TRUCK_BREAK_OFF', 'FROMDATE', 'TODATE', 'FROMMEASURE', 'TOMEASURE']])\n",
    "# Data preprocessing complete\n",
    "print('Dataset:\\n', df.head(5))\n",
    "\n",
    "# create train test split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=200)\n",
    "\n",
    "print()\n",
    "print('Train set:\\n', train.shape)\n",
    "print('Test set:\\n', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing datesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train-V1.csv', index=False)\n",
    "test.to_csv('test-V1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send test/train datasets to Sagemaker\n",
    "We will send the test/train datasets into sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/train-V1.csv\n",
      "s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/datasets/test-V1.csv\n"
     ]
    }
   ],
   "source": [
    "# send to s3 bucket. Sagemaker will take training data from the S3 bucket\n",
    "sk_prefix = \"sagemaker/truck-break-off-rl_markov/datasets\"\n",
    "train_path = sess.upload_data(path='train-V1.csv', bucket= bucket, key_prefix=sk_prefix)\n",
    "test_path = sess.upload_data(path='test-V1.csv', bucket= bucket, key_prefix=sk_prefix)\n",
    "\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

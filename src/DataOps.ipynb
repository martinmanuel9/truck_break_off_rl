{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataOps onto S3 Bucket in AWS\n",
    "The intent of this notebook is to develop a test/train datasets for Sagemaker Studio. This notebook goes step-by-step on ingesting data onto an S3 bucket so that we can connect to Sagemaker. This component addresses data engineer, feature selection, and feature extraction and provides a Data Scientist the test/train datasets to begin experimentation, model training, and begin the data science work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/martinlopez/Library/Application Support/sagemaker/config.yaml\n",
      "Using bucket martymdlregistry\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# creating a client for sagemaker\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "# creating a session for sagemaker\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Need to create an S3 bucket\n",
    "bucket = 'martymdlregistry' # specific s3 bucket\n",
    "print('Using bucket ' + bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Information\n",
    "We have downloaded the Metro DC Truck routes from the following source: https://opendata.dc.gov/datasets/DCGIS::truck-and-bus-through-route/about \n",
    "\n",
    "We now initialize the dataset and conduct featur development and develop synthetic data. The synthetic data we include is the labels as well as the truck_break_off flag. This should emulate when a truck successfully broke off from the route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/martinlopez/Documents/GitHub/truck_break_off_rl/src\n",
      "Dataset:\n",
      "             NAME   ROUTEID  FROMMEASURE   TOMEASURE                FROMDATE  \\\n",
      "0  Primary Route  0.032468    9899.5123   9988.3999  2019/01/01 00:00:00+00   \n",
      "1  Primary Route  0.032468    7773.7123   7797.1786  2019/01/01 00:00:00+00   \n",
      "2  Primary Route  0.032468    1104.9776   1187.2989  2019/01/01 00:00:00+00   \n",
      "3  Primary Route  0.032468   10277.8444  10287.2693  2019/01/01 00:00:00+00   \n",
      "4  Primary Route  0.032468    7972.7124   8057.2873  2019/01/01 00:00:00+00   \n",
      "\n",
      "   TODATE                                 EVENTID  LOCERROR CREATED_USER  \\\n",
      "0     NaN  {95A11B7D-E871-4A60-841D-4EE8B490B7D1}  NO ERROR          NaN   \n",
      "1     NaN  {7108E69C-3464-4FF5-8A2E-38EF961B2E23}  NO ERROR          NaN   \n",
      "2     NaN  {9AE842B8-98E4-4D5B-9EE8-73AE4CE25B25}  NO ERROR          NaN   \n",
      "3     NaN  {0555805C-A411-4FD0-BD99-6E3D5AE1446C}  NO ERROR          NaN   \n",
      "4     NaN  {279C06E7-BC10-4BF6-A49D-A185FC44132D}  NO ERROR          NaN   \n",
      "\n",
      "  CREATED_DATE LAST_EDITED_USER  LAST_EDITED_DATE  SE_ANNO_CAD_DATA  OBJECTID  \\\n",
      "0          NaN               RH      4.173894e-08               NaN    151682   \n",
      "1          NaN               RH      4.173894e-08               NaN    151683   \n",
      "2          NaN               RH      4.173894e-08               NaN    151684   \n",
      "3          NaN               RH      4.173894e-08               NaN    151685   \n",
      "4          NaN               RH      4.173894e-08               NaN    151686   \n",
      "\n",
      "   SHAPE  SHAPELEN  TRUCK_BREAK_OFF  LABEL  \n",
      "0    NaN         0              1.0      1  \n",
      "1    NaN         0              0.0      0  \n",
      "2    NaN         0              1.0      0  \n",
      "3    NaN         0              1.0      1  \n",
      "4    NaN         0              1.0      0  \n",
      "Train set:\n",
      " (1636, 18)\n",
      "Test set:\n",
      " (410, 18)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(os.getcwd())\n",
    "# Change the directory to 'dataset'\n",
    "os.chdir('../dataset')\n",
    "# Path to the CSV file\n",
    "csv_file = 'Truck_and_Bus_Through_Route.csv'\n",
    "\n",
    "# Read the CSV file into a dataframe\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# define feature TRUCK_BREAK_OFF\n",
    "df['TRUCK_BREAK_OFF'] = 0\n",
    "# capture labels\n",
    "df['LABEL'] = 0\n",
    "df['LABEL'] = [random.randint(0, 1) for _ in range(len(df))]\n",
    "\n",
    "# Randomize 0s and 1s for the column TRUCK_BREAK_OFF\n",
    "df['TRUCK_BREAK_OFF'] = [random.randint(0, 1) for _ in range(len(df))]\n",
    "\n",
    "    # Data preprocessing\n",
    "df['LAST_EDITED_DATE'] = pd.to_datetime(df['LAST_EDITED_DATE'])\n",
    "# Convert datetime to Unix timestamp\n",
    "df['LAST_EDITED_DATE'] = df['LAST_EDITED_DATE'].astype(int)\n",
    "df['ROUTEID'] = df['ROUTEID'].astype('category').cat.codes\n",
    "\n",
    "## normalization and feature selection\n",
    "scaler = MinMaxScaler()\n",
    "df[['ROUTEID','LAST_EDITED_DATE','TRUCK_BREAK_OFF']] = scaler.fit_transform(df[['ROUTEID','LAST_EDITED_DATE','TRUCK_BREAK_OFF']])\n",
    "\n",
    "# Data preprocessing complete\n",
    "print('Dataset:\\n', df.head(5))\n",
    "\n",
    "# create train test split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=200)\n",
    "\n",
    "\n",
    "print('Train set:\\n', train.shape)\n",
    "print('Test set:\\n', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing datesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train-V1.csv', index=False)\n",
    "test.to_csv('test-V1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send test/train datasets to Sagemaker\n",
    "We will send the test/train datasets into sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/train-V1.csv\n",
      "s3://martymdlregistry/sagemaker/truck-break-off-rl_markov/test-V1.csv\n"
     ]
    }
   ],
   "source": [
    "# send to s3 bucket. Sagemaker will take training data from the S3 bucket\n",
    "sk_prefix = \"sagemaker/truck-break-off-rl_markov\"\n",
    "train_path = sess.upload_data(path='train-V1.csv', bucket= bucket, key_prefix=sk_prefix)\n",
    "test_path = sess.upload_data(path='test-V1.csv', bucket= bucket, key_prefix=sk_prefix)\n",
    "\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
